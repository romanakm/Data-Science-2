{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Dict, List, Optional, Sequence, TextIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")  # Report only TF errors by default\n",
    "\n",
    "from DS_2_2022_HW2_efficient_net import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Height, width and number of channels\n",
    "H: int = 224\n",
    "W: int = 224\n",
    "C: int = 3\n",
    "LABELS: int = 34\n",
    "    \n",
    "# Declare functions\n",
    "def parse(example) -> Dict[str, tf.Tensor]:\n",
    "    example = tf.io.parse_single_example(example, {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"mask\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64)})\n",
    "    example[\"image\"] = tf.image.convert_image_dtype(tf.image.decode_jpeg(example[\"image\"], channels=3), tf.float32)\n",
    "    example[\"mask\"] = tf.image.convert_image_dtype(tf.image.decode_png(example[\"mask\"], channels=1), tf.float32)\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data. Train & Dev datasets are stored as tfrecord objects (see https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset)-\n",
    "train = tf.data.TFRecordDataset(\"hw2_trainsample.tfrecord\")\n",
    "dev = tf.data.TFRecordDataset(\"hw2_devsample.tfrecord\")\n",
    "    \n",
    "# Process data. Train & Dev are decoded from jpeg; Test data are constructed from list.\n",
    "train = train.map(parse)\n",
    "dev = dev.map(parse)\n",
    "\n",
    "test = tf.data.Dataset.from_tensor_slices(test) # see https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "\n",
    "Continue by initializing EfficientNet, building the model, augmentation and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call constructor of EfficientNet and call your object 'base_model'. You need to specify several parameters:\n",
    "# - width_coefficient, depth_coefficient: determine the scale for depth and width of the network. Reasonable to start with both equal to 1.0\n",
    "# - default_resolution: resolution of an input image\n",
    "# - dropout_rate: dropout rate used throughout the network\n",
    "# - include_top: if True then the network will include the final classification layer and produce a prediction for 1000 classes in ImageNet classification dataset,\n",
    "# if False, the network will return 'image features' (the result of the last global average pooling)\n",
    "# weights: path to the file for pre-trained weights. Use 'efficientnet.h5' that you have downloaded from the Kaggle competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling constuctor of EfficientNet you have constructed a tf.keras.Model object. \n",
    "# Iterate over layers of that model and set their attribute 'trainable' to False for most of them,\n",
    "# (in this way you will train only some of the large number of parameters; - is it reasonable to train the first or the last layers?)\n",
    "# Use method .summary() to investigate the number of trainable and non-trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use API logic seen on the practicals to build the following model:\n",
    "# The input layer takes images with 3 channels and passes them to the initialized EfficientNet model\n",
    "# After processing through Efficient model, add few more fully connected layers, with regularization of your choice\n",
    "# Output of your model should be a vector of probabilities for each of the breed.\n",
    "\n",
    "inputs = tf.keras.layers.Input([H, W, C])\n",
    "hidden = base_model(inputs)[0]\n",
    "hidden = ... # continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define pipeline that will consist of augmentation and batching\n",
    "\n",
    "def augment_train(input):\n",
    "    image = input['image']\n",
    "    label = input['label']\n",
    "    \n",
    "    # Augmentation procedures (modify to your wish)\n",
    "\n",
    "    image = tf.image.random_jpeg_quality(image,80,100)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_crop(image, [CAGS.H, CAGS.W, CAGS.C])\n",
    "\n",
    "    return image, label\n",
    "\n",
    "def augment_dev(input):\n",
    "    image = input['image']\n",
    "    label = input['label']\n",
    "    \n",
    "    # Augmentation procedures (add to your wish)\n",
    "    # Note: if we add augmentation also to dev dataset, we can assume that\n",
    "    # performance of test dataset will be better as test dataset is not augmented\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Now we apply augmentation using .map()\n",
    "train = ...\n",
    "dev = ...\n",
    "\n",
    "# Apply .batch() to 'train' and 'dev' with some choice of batch size\n",
    "train = ...\n",
    "dev = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit your model using early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "Load test dataset, predict labels and store results. Note that (for educational purposes) we load the data from pickled list. Therefore, transformation to Tensorflow dataset has to be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset stored as pickled list.\n",
    "with open('hw2_outofsample.pickle', 'rb') as handle:\n",
    "    test = pickle.load(handle)\n",
    "\n",
    "# Produce dataset from list\n",
    "test = tf.data.Dataset.from_tensor_slices(test)\n",
    "\n",
    "# Apply batching also to 'test'\n",
    "test = ...\n",
    "\n",
    "# Predict\n",
    "test_prediction_prob = model.predict(test)\n",
    "test_prediction = [\n",
    "    np.argmax(probs) for probs in test_prediction_prob\n",
    "]\n",
    "\n",
    "# Store results\n",
    "pd.DataFrame({'prediction': test_prediction}).to_csv('data/hw2_outofsample_prediction.csv', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "223px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}